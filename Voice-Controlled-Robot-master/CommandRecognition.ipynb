{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install librosa\n",
    "#!{sys.executable} -m pip install numpy\n",
    "#!{sys.executable} -m pip install scipy\n",
    "#!{sys.executable} -m pip install keras\n",
    "#!{sys.executable} -m pip install tensorflow\n",
    "#!{sys.executable} -m pip install scikit-learn\n",
    "import numpy as np, keras, librosa, tensorflow, scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2mfcc(file_path, max_pad_len=11):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    wave = wave[::3]\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "    if (max_pad_len>mfcc.shape[1]):\n",
    "        pad_width = max_pad_len-mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0,0),(0,pad_width)),mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:,:max_pad_len]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "DATA_PATH = \"/home/aaa/aatresh/Audio Processing/data/\"\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, keras.utils.to_categorical(label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_array(path=DATA_PATH, max_pad_len=11):\n",
    "    labels,_,_= get_labels(path)\n",
    "    \n",
    "    for label in labels:\n",
    "        mfcc_vectors = []\n",
    "        \n",
    "        wavfiles = [path+label+'/'+wavfile for wavfile in os.listdir(path+'/'+label)]\n",
    "        for wavfile in wavfiles:\n",
    "            mfcc = wav2mfcc(wavfile, max_pad_len=max_pad_len)\n",
    "            mfcc_vectors.append(mfcc)\n",
    "            \n",
    "        np.save(label+'.npy',mfcc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def get_train_test(split_ratio=0.6, random_state=42):\n",
    "    labels, indices,_ = get_labels(DATA_PATH)\n",
    "    \n",
    "    X = np.load(labels[0]+'.npy')\n",
    "    y = np.zeros(X.shape[0])\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label+'.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value=(i+1)))\n",
    "        \n",
    "    assert X.shape[0] == len(y)\n",
    "    \n",
    "    return train_test_split(X, y, test_size=(1-split_ratio),random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "X_train = X_train.reshape(X_train.shape[0], 20, 11, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 20, 11, 1)\n",
    "y_train_hot = keras.utils.to_categorical(y_train)\n",
    "y_test_hot = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5683 samples, validate on 3789 samples\n",
      "Epoch 1/300\n",
      "5683/5683 [==============================] - 1s 167us/step - loss: 7.7192 - acc: 0.3400 - val_loss: 1.2700 - val_acc: 0.4178\n",
      "Epoch 2/300\n",
      "5683/5683 [==============================] - 1s 128us/step - loss: 1.2896 - acc: 0.4408 - val_loss: 1.0104 - val_acc: 0.5838\n",
      "Epoch 3/300\n",
      "5683/5683 [==============================] - 1s 126us/step - loss: 1.0974 - acc: 0.5224 - val_loss: 0.9410 - val_acc: 0.6091\n",
      "Epoch 4/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.9763 - acc: 0.5747 - val_loss: 0.8374 - val_acc: 0.6791\n",
      "Epoch 5/300\n",
      "5683/5683 [==============================] - 1s 122us/step - loss: 0.9216 - acc: 0.6021 - val_loss: 0.7123 - val_acc: 0.7092\n",
      "Epoch 6/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.8638 - acc: 0.6307 - val_loss: 0.7050 - val_acc: 0.7202\n",
      "Epoch 7/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.8025 - acc: 0.6622 - val_loss: 0.6762 - val_acc: 0.7089\n",
      "Epoch 8/300\n",
      "5683/5683 [==============================] - 1s 124us/step - loss: 0.7567 - acc: 0.6827 - val_loss: 0.6094 - val_acc: 0.7493\n",
      "Epoch 9/300\n",
      "5683/5683 [==============================] - 1s 115us/step - loss: 0.7300 - acc: 0.6998 - val_loss: 0.5831 - val_acc: 0.7754\n",
      "Epoch 10/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.6959 - acc: 0.7142 - val_loss: 0.5444 - val_acc: 0.7928\n",
      "Epoch 11/300\n",
      "5683/5683 [==============================] - 1s 127us/step - loss: 0.6587 - acc: 0.7260 - val_loss: 0.4947 - val_acc: 0.8073\n",
      "Epoch 12/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.6290 - acc: 0.7457 - val_loss: 0.4857 - val_acc: 0.8110\n",
      "Epoch 13/300\n",
      "5683/5683 [==============================] - 1s 127us/step - loss: 0.6069 - acc: 0.7628 - val_loss: 0.4916 - val_acc: 0.8189\n",
      "Epoch 14/300\n",
      "5683/5683 [==============================] - 1s 123us/step - loss: 0.5555 - acc: 0.7776 - val_loss: 0.4443 - val_acc: 0.8430\n",
      "Epoch 15/300\n",
      "5683/5683 [==============================] - 1s 121us/step - loss: 0.5505 - acc: 0.7829 - val_loss: 0.4245 - val_acc: 0.8401\n",
      "Epoch 16/300\n",
      "5683/5683 [==============================] - 1s 116us/step - loss: 0.5043 - acc: 0.8042 - val_loss: 0.4084 - val_acc: 0.8411\n",
      "Epoch 17/300\n",
      "5683/5683 [==============================] - 1s 123us/step - loss: 0.4782 - acc: 0.8130 - val_loss: 0.4092 - val_acc: 0.8401\n",
      "Epoch 18/300\n",
      "5683/5683 [==============================] - 1s 120us/step - loss: 0.4855 - acc: 0.8082 - val_loss: 0.3779 - val_acc: 0.8606\n",
      "Epoch 19/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.4689 - acc: 0.8205 - val_loss: 0.4028 - val_acc: 0.8440\n",
      "Epoch 20/300\n",
      "5683/5683 [==============================] - 1s 121us/step - loss: 0.4328 - acc: 0.8344 - val_loss: 0.3943 - val_acc: 0.8501\n",
      "Epoch 21/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.4302 - acc: 0.8386 - val_loss: 0.3577 - val_acc: 0.8596\n",
      "Epoch 22/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.4154 - acc: 0.8399 - val_loss: 0.3694 - val_acc: 0.8577\n",
      "Epoch 23/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.3958 - acc: 0.8455 - val_loss: 0.3485 - val_acc: 0.8628\n",
      "Epoch 24/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.4017 - acc: 0.8400 - val_loss: 0.3524 - val_acc: 0.8694\n",
      "Epoch 25/300\n",
      "5683/5683 [==============================] - 1s 116us/step - loss: 0.3618 - acc: 0.8592 - val_loss: 0.3263 - val_acc: 0.8754\n",
      "Epoch 26/300\n",
      "5683/5683 [==============================] - 1s 129us/step - loss: 0.3713 - acc: 0.8562 - val_loss: 0.3124 - val_acc: 0.8815\n",
      "Epoch 27/300\n",
      "5683/5683 [==============================] - 1s 130us/step - loss: 0.3535 - acc: 0.8631 - val_loss: 0.3256 - val_acc: 0.8797\n",
      "Epoch 28/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.3402 - acc: 0.8656 - val_loss: 0.3025 - val_acc: 0.8857\n",
      "Epoch 29/300\n",
      "5683/5683 [==============================] - 1s 123us/step - loss: 0.3430 - acc: 0.8684 - val_loss: 0.2950 - val_acc: 0.8862\n",
      "Epoch 30/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.3289 - acc: 0.8768 - val_loss: 0.3504 - val_acc: 0.8649\n",
      "Epoch 31/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.3399 - acc: 0.8731 - val_loss: 0.3241 - val_acc: 0.8812\n",
      "Epoch 32/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.3197 - acc: 0.8775 - val_loss: 0.3133 - val_acc: 0.8849\n",
      "Epoch 33/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.3099 - acc: 0.8793 - val_loss: 0.3046 - val_acc: 0.8868\n",
      "Epoch 34/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.3109 - acc: 0.8800 - val_loss: 0.3140 - val_acc: 0.8789\n",
      "Epoch 35/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.2964 - acc: 0.8877 - val_loss: 0.2833 - val_acc: 0.8907\n",
      "Epoch 36/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.3015 - acc: 0.8860 - val_loss: 0.2924 - val_acc: 0.8923\n",
      "Epoch 37/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.2829 - acc: 0.8955 - val_loss: 0.2803 - val_acc: 0.8923\n",
      "Epoch 38/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.2804 - acc: 0.8879 - val_loss: 0.2998 - val_acc: 0.8910\n",
      "Epoch 39/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.2698 - acc: 0.8946 - val_loss: 0.2838 - val_acc: 0.8894\n",
      "Epoch 40/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.2769 - acc: 0.8953 - val_loss: 0.2857 - val_acc: 0.8926\n",
      "Epoch 41/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.2656 - acc: 0.8967 - val_loss: 0.2894 - val_acc: 0.8931\n",
      "Epoch 42/300\n",
      "5683/5683 [==============================] - 1s 125us/step - loss: 0.2567 - acc: 0.9016 - val_loss: 0.2932 - val_acc: 0.8897\n",
      "Epoch 43/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.2674 - acc: 0.8965 - val_loss: 0.2876 - val_acc: 0.8907\n",
      "Epoch 44/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.2499 - acc: 0.9052 - val_loss: 0.2955 - val_acc: 0.8910\n",
      "Epoch 45/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.2537 - acc: 0.9064 - val_loss: 0.2904 - val_acc: 0.8889\n",
      "Epoch 46/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.2522 - acc: 0.9041 - val_loss: 0.2640 - val_acc: 0.9060\n",
      "Epoch 47/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.2449 - acc: 0.9060 - val_loss: 0.3064 - val_acc: 0.8907\n",
      "Epoch 48/300\n",
      "5683/5683 [==============================] - 1s 127us/step - loss: 0.2535 - acc: 0.9004 - val_loss: 0.2610 - val_acc: 0.9016\n",
      "Epoch 49/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.2406 - acc: 0.9104 - val_loss: 0.2808 - val_acc: 0.8928\n",
      "Epoch 50/300\n",
      "5683/5683 [==============================] - 1s 135us/step - loss: 0.2228 - acc: 0.9173 - val_loss: 0.3100 - val_acc: 0.8921\n",
      "Epoch 51/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.2249 - acc: 0.9154 - val_loss: 0.2755 - val_acc: 0.9008\n",
      "Epoch 52/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.2298 - acc: 0.9111 - val_loss: 0.2940 - val_acc: 0.8921\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.2282 - acc: 0.9184 - val_loss: 0.2614 - val_acc: 0.8997\n",
      "Epoch 54/300\n",
      "5683/5683 [==============================] - 1s 109us/step - loss: 0.2200 - acc: 0.9162 - val_loss: 0.2697 - val_acc: 0.9063\n",
      "Epoch 55/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.2235 - acc: 0.9173 - val_loss: 0.2981 - val_acc: 0.8926\n",
      "Epoch 56/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.2251 - acc: 0.9145 - val_loss: 0.3061 - val_acc: 0.8918\n",
      "Epoch 57/300\n",
      "5683/5683 [==============================] - 1s 129us/step - loss: 0.2051 - acc: 0.9212 - val_loss: 0.2803 - val_acc: 0.8984\n",
      "Epoch 58/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.1991 - acc: 0.9233 - val_loss: 0.2681 - val_acc: 0.9023\n",
      "Epoch 59/300\n",
      "5683/5683 [==============================] - 1s 125us/step - loss: 0.2089 - acc: 0.9222 - val_loss: 0.2797 - val_acc: 0.9013\n",
      "Epoch 60/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.2010 - acc: 0.9210 - val_loss: 0.2772 - val_acc: 0.9047\n",
      "Epoch 61/300\n",
      "5683/5683 [==============================] - 1s 109us/step - loss: 0.1978 - acc: 0.9286 - val_loss: 0.2937 - val_acc: 0.9002\n",
      "Epoch 62/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.2184 - acc: 0.9185 - val_loss: 0.2935 - val_acc: 0.8973\n",
      "Epoch 63/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.2043 - acc: 0.9228 - val_loss: 0.2662 - val_acc: 0.9021\n",
      "Epoch 64/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.1956 - acc: 0.9275 - val_loss: 0.3323 - val_acc: 0.8878\n",
      "Epoch 65/300\n",
      "5683/5683 [==============================] - 1s 122us/step - loss: 0.1856 - acc: 0.9308 - val_loss: 0.2950 - val_acc: 0.8960\n",
      "Epoch 66/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.1924 - acc: 0.9286 - val_loss: 0.2906 - val_acc: 0.8979\n",
      "Epoch 67/300\n",
      "5683/5683 [==============================] - 1s 129us/step - loss: 0.1897 - acc: 0.9303 - val_loss: 0.2985 - val_acc: 0.8976\n",
      "Epoch 68/300\n",
      "5683/5683 [==============================] - 1s 120us/step - loss: 0.1853 - acc: 0.9303 - val_loss: 0.2761 - val_acc: 0.9031\n",
      "Epoch 69/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.1814 - acc: 0.9321 - val_loss: 0.2924 - val_acc: 0.9008\n",
      "Epoch 70/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.1911 - acc: 0.9287 - val_loss: 0.2729 - val_acc: 0.9042\n",
      "Epoch 71/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.1872 - acc: 0.9298 - val_loss: 0.2820 - val_acc: 0.9023\n",
      "Epoch 72/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.1792 - acc: 0.9316 - val_loss: 0.2861 - val_acc: 0.8992\n",
      "Epoch 73/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.1799 - acc: 0.9282 - val_loss: 0.3095 - val_acc: 0.8944\n",
      "Epoch 74/300\n",
      "5683/5683 [==============================] - 1s 129us/step - loss: 0.1836 - acc: 0.9298 - val_loss: 0.2766 - val_acc: 0.9053\n",
      "Epoch 75/300\n",
      "5683/5683 [==============================] - 1s 140us/step - loss: 0.1670 - acc: 0.9326 - val_loss: 0.3028 - val_acc: 0.8955\n",
      "Epoch 76/300\n",
      "5683/5683 [==============================] - 1s 134us/step - loss: 0.1676 - acc: 0.9367 - val_loss: 0.2902 - val_acc: 0.9005\n",
      "Epoch 77/300\n",
      "5683/5683 [==============================] - 1s 146us/step - loss: 0.1730 - acc: 0.9395 - val_loss: 0.2678 - val_acc: 0.9053\n",
      "Epoch 78/300\n",
      "5683/5683 [==============================] - 1s 136us/step - loss: 0.1691 - acc: 0.9396 - val_loss: 0.2656 - val_acc: 0.9074\n",
      "Epoch 79/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.1642 - acc: 0.9372 - val_loss: 0.2835 - val_acc: 0.9053\n",
      "Epoch 80/300\n",
      "5683/5683 [==============================] - 1s 121us/step - loss: 0.1564 - acc: 0.9421 - val_loss: 0.2938 - val_acc: 0.8971\n",
      "Epoch 81/300\n",
      "5683/5683 [==============================] - 1s 129us/step - loss: 0.1788 - acc: 0.9356 - val_loss: 0.2846 - val_acc: 0.9037\n",
      "Epoch 82/300\n",
      "5683/5683 [==============================] - 1s 125us/step - loss: 0.1568 - acc: 0.9405 - val_loss: 0.3356 - val_acc: 0.8910\n",
      "Epoch 83/300\n",
      "5683/5683 [==============================] - 1s 134us/step - loss: 0.1608 - acc: 0.9382 - val_loss: 0.2822 - val_acc: 0.9031\n",
      "Epoch 84/300\n",
      "5683/5683 [==============================] - 1s 149us/step - loss: 0.1754 - acc: 0.9340 - val_loss: 0.3036 - val_acc: 0.8950\n",
      "Epoch 85/300\n",
      "5683/5683 [==============================] - 1s 154us/step - loss: 0.1490 - acc: 0.9418 - val_loss: 0.2796 - val_acc: 0.9058\n",
      "Epoch 86/300\n",
      "5683/5683 [==============================] - 1s 156us/step - loss: 0.1616 - acc: 0.9388 - val_loss: 0.2933 - val_acc: 0.9042\n",
      "Epoch 87/300\n",
      "5683/5683 [==============================] - 1s 137us/step - loss: 0.1508 - acc: 0.9444 - val_loss: 0.2746 - val_acc: 0.9037\n",
      "Epoch 88/300\n",
      "5683/5683 [==============================] - 1s 121us/step - loss: 0.1561 - acc: 0.9426 - val_loss: 0.2857 - val_acc: 0.9029\n",
      "Epoch 89/300\n",
      "5683/5683 [==============================] - 1s 120us/step - loss: 0.1590 - acc: 0.9386 - val_loss: 0.2873 - val_acc: 0.8984\n",
      "Epoch 90/300\n",
      "5683/5683 [==============================] - 1s 121us/step - loss: 0.1423 - acc: 0.9428 - val_loss: 0.2889 - val_acc: 0.9066\n",
      "Epoch 91/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.1481 - acc: 0.9453 - val_loss: 0.2828 - val_acc: 0.9047\n",
      "Epoch 92/300\n",
      "5683/5683 [==============================] - 1s 137us/step - loss: 0.1436 - acc: 0.9460 - val_loss: 0.2913 - val_acc: 0.9058\n",
      "Epoch 93/300\n",
      "5683/5683 [==============================] - 1s 141us/step - loss: 0.1534 - acc: 0.9456 - val_loss: 0.2740 - val_acc: 0.9039\n",
      "Epoch 94/300\n",
      "5683/5683 [==============================] - 1s 140us/step - loss: 0.1488 - acc: 0.9437 - val_loss: 0.2880 - val_acc: 0.9042\n",
      "Epoch 95/300\n",
      "5683/5683 [==============================] - 1s 145us/step - loss: 0.1449 - acc: 0.9428 - val_loss: 0.2865 - val_acc: 0.9082\n",
      "Epoch 96/300\n",
      "5683/5683 [==============================] - 1s 145us/step - loss: 0.1447 - acc: 0.9497 - val_loss: 0.2898 - val_acc: 0.9029\n",
      "Epoch 97/300\n",
      "5683/5683 [==============================] - 1s 128us/step - loss: 0.1432 - acc: 0.9460 - val_loss: 0.2983 - val_acc: 0.9034\n",
      "Epoch 98/300\n",
      "5683/5683 [==============================] - 1s 129us/step - loss: 0.1559 - acc: 0.9447 - val_loss: 0.2789 - val_acc: 0.9023\n",
      "Epoch 99/300\n",
      "5683/5683 [==============================] - 1s 122us/step - loss: 0.1265 - acc: 0.9551 - val_loss: 0.2887 - val_acc: 0.9045\n",
      "Epoch 100/300\n",
      "5683/5683 [==============================] - 1s 120us/step - loss: 0.1395 - acc: 0.9474 - val_loss: 0.2809 - val_acc: 0.9060\n",
      "Epoch 101/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.1466 - acc: 0.9455 - val_loss: 0.2937 - val_acc: 0.9021\n",
      "Epoch 102/300\n",
      "5683/5683 [==============================] - 1s 141us/step - loss: 0.1275 - acc: 0.9557 - val_loss: 0.3007 - val_acc: 0.9047\n",
      "Epoch 103/300\n",
      "5683/5683 [==============================] - 1s 139us/step - loss: 0.1276 - acc: 0.9546 - val_loss: 0.3077 - val_acc: 0.9042\n",
      "Epoch 104/300\n",
      "5683/5683 [==============================] - 1s 142us/step - loss: 0.1293 - acc: 0.9514 - val_loss: 0.2884 - val_acc: 0.9055\n",
      "Epoch 105/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.1367 - acc: 0.9486 - val_loss: 0.2820 - val_acc: 0.9060\n",
      "Epoch 106/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.1322 - acc: 0.9493 - val_loss: 0.3191 - val_acc: 0.9000\n",
      "Epoch 107/300\n",
      "5683/5683 [==============================] - 1s 122us/step - loss: 0.1258 - acc: 0.9516 - val_loss: 0.3208 - val_acc: 0.8955\n",
      "Epoch 108/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.1347 - acc: 0.9486 - val_loss: 0.2845 - val_acc: 0.9084\n",
      "Epoch 109/300\n",
      "5683/5683 [==============================] - 1s 120us/step - loss: 0.1390 - acc: 0.9504 - val_loss: 0.2955 - val_acc: 0.9013\n",
      "Epoch 110/300\n",
      "5683/5683 [==============================] - 1s 124us/step - loss: 0.1265 - acc: 0.9527 - val_loss: 0.2898 - val_acc: 0.9037\n",
      "Epoch 111/300\n",
      "5683/5683 [==============================] - 1s 141us/step - loss: 0.1427 - acc: 0.9509 - val_loss: 0.2924 - val_acc: 0.9053\n",
      "Epoch 112/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5683/5683 [==============================] - 1s 134us/step - loss: 0.1290 - acc: 0.9518 - val_loss: 0.2843 - val_acc: 0.9076\n",
      "Epoch 113/300\n",
      "5683/5683 [==============================] - 1s 129us/step - loss: 0.1316 - acc: 0.9516 - val_loss: 0.2976 - val_acc: 0.8992\n",
      "Epoch 114/300\n",
      "5683/5683 [==============================] - 1s 130us/step - loss: 0.1191 - acc: 0.9539 - val_loss: 0.3140 - val_acc: 0.9060\n",
      "Epoch 115/300\n",
      "5683/5683 [==============================] - 1s 116us/step - loss: 0.1305 - acc: 0.9537 - val_loss: 0.3126 - val_acc: 0.9039\n",
      "Epoch 116/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.1213 - acc: 0.9546 - val_loss: 0.3077 - val_acc: 0.9000\n",
      "Epoch 117/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.1190 - acc: 0.9578 - val_loss: 0.3384 - val_acc: 0.9005\n",
      "Epoch 118/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.1193 - acc: 0.9555 - val_loss: 0.3005 - val_acc: 0.9042\n",
      "Epoch 119/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.1242 - acc: 0.9553 - val_loss: 0.2962 - val_acc: 0.9039\n",
      "Epoch 120/300\n",
      "5683/5683 [==============================] - 1s 116us/step - loss: 0.1219 - acc: 0.9544 - val_loss: 0.3034 - val_acc: 0.9031\n",
      "Epoch 121/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.1212 - acc: 0.9590 - val_loss: 0.3122 - val_acc: 0.9026\n",
      "Epoch 122/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.1242 - acc: 0.9558 - val_loss: 0.3091 - val_acc: 0.9042\n",
      "Epoch 123/300\n",
      "5683/5683 [==============================] - 1s 130us/step - loss: 0.1143 - acc: 0.9599 - val_loss: 0.3114 - val_acc: 0.9053\n",
      "Epoch 124/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.1128 - acc: 0.9595 - val_loss: 0.3263 - val_acc: 0.9037\n",
      "Epoch 125/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.1227 - acc: 0.9548 - val_loss: 0.2870 - val_acc: 0.9060\n",
      "Epoch 126/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.1172 - acc: 0.9616 - val_loss: 0.3071 - val_acc: 0.9074\n",
      "Epoch 127/300\n",
      "5683/5683 [==============================] - 1s 127us/step - loss: 0.1236 - acc: 0.9548 - val_loss: 0.3138 - val_acc: 0.9002\n",
      "Epoch 128/300\n",
      "5683/5683 [==============================] - 1s 127us/step - loss: 0.1268 - acc: 0.9553 - val_loss: 0.2932 - val_acc: 0.9050\n",
      "Epoch 129/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.1262 - acc: 0.9550 - val_loss: 0.3105 - val_acc: 0.9074\n",
      "Epoch 130/300\n",
      "5683/5683 [==============================] - 1s 134us/step - loss: 0.1127 - acc: 0.9576 - val_loss: 0.3266 - val_acc: 0.9042\n",
      "Epoch 131/300\n",
      "5683/5683 [==============================] - 1s 144us/step - loss: 0.1235 - acc: 0.9564 - val_loss: 0.2948 - val_acc: 0.9105\n",
      "Epoch 132/300\n",
      "5683/5683 [==============================] - 1s 144us/step - loss: 0.1182 - acc: 0.9546 - val_loss: 0.2865 - val_acc: 0.9087\n",
      "Epoch 133/300\n",
      "5683/5683 [==============================] - 1s 137us/step - loss: 0.1203 - acc: 0.9564 - val_loss: 0.3229 - val_acc: 0.9063\n",
      "Epoch 134/300\n",
      "5683/5683 [==============================] - 1s 133us/step - loss: 0.1182 - acc: 0.9571 - val_loss: 0.3027 - val_acc: 0.9079\n",
      "Epoch 135/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.1088 - acc: 0.9618 - val_loss: 0.3024 - val_acc: 0.9082\n",
      "Epoch 136/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.1098 - acc: 0.9620 - val_loss: 0.2885 - val_acc: 0.9105\n",
      "Epoch 137/300\n",
      "5683/5683 [==============================] - 1s 120us/step - loss: 0.1020 - acc: 0.9615 - val_loss: 0.3095 - val_acc: 0.9066\n",
      "Epoch 138/300\n",
      "5683/5683 [==============================] - 1s 120us/step - loss: 0.1177 - acc: 0.9576 - val_loss: 0.3237 - val_acc: 0.9034\n",
      "Epoch 139/300\n",
      "5683/5683 [==============================] - 1s 121us/step - loss: 0.1117 - acc: 0.9599 - val_loss: 0.3138 - val_acc: 0.9060\n",
      "Epoch 140/300\n",
      "5683/5683 [==============================] - 1s 137us/step - loss: 0.1146 - acc: 0.9592 - val_loss: 0.2820 - val_acc: 0.9079\n",
      "Epoch 141/300\n",
      "5683/5683 [==============================] - 1s 138us/step - loss: 0.1130 - acc: 0.9615 - val_loss: 0.3198 - val_acc: 0.9045\n",
      "Epoch 142/300\n",
      "5683/5683 [==============================] - 1s 139us/step - loss: 0.1047 - acc: 0.9616 - val_loss: 0.3067 - val_acc: 0.9066\n",
      "Epoch 143/300\n",
      "5683/5683 [==============================] - 1s 141us/step - loss: 0.1063 - acc: 0.9636 - val_loss: 0.3208 - val_acc: 0.8992\n",
      "Epoch 144/300\n",
      "5683/5683 [==============================] - 1s 124us/step - loss: 0.1094 - acc: 0.9620 - val_loss: 0.3427 - val_acc: 0.8981\n",
      "Epoch 145/300\n",
      "5683/5683 [==============================] - 1s 121us/step - loss: 0.1156 - acc: 0.9592 - val_loss: 0.3234 - val_acc: 0.9058\n",
      "Epoch 146/300\n",
      "5683/5683 [==============================] - 1s 120us/step - loss: 0.1067 - acc: 0.9595 - val_loss: 0.3279 - val_acc: 0.9042\n",
      "Epoch 147/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.0966 - acc: 0.9659 - val_loss: 0.3187 - val_acc: 0.9076\n",
      "Epoch 148/300\n",
      "5683/5683 [==============================] - 1s 120us/step - loss: 0.1141 - acc: 0.9594 - val_loss: 0.2975 - val_acc: 0.9092\n",
      "Epoch 149/300\n",
      "5683/5683 [==============================] - 1s 134us/step - loss: 0.0990 - acc: 0.9622 - val_loss: 0.3188 - val_acc: 0.9089\n",
      "Epoch 150/300\n",
      "5683/5683 [==============================] - 1s 138us/step - loss: 0.1003 - acc: 0.9629 - val_loss: 0.3114 - val_acc: 0.9042\n",
      "Epoch 151/300\n",
      "5683/5683 [==============================] - 1s 139us/step - loss: 0.1018 - acc: 0.9662 - val_loss: 0.3046 - val_acc: 0.9100\n",
      "Epoch 152/300\n",
      "5683/5683 [==============================] - 1s 140us/step - loss: 0.1124 - acc: 0.9613 - val_loss: 0.3104 - val_acc: 0.9076\n",
      "Epoch 153/300\n",
      "5683/5683 [==============================] - 1s 129us/step - loss: 0.0948 - acc: 0.9664 - val_loss: 0.3151 - val_acc: 0.9100\n",
      "Epoch 154/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.0996 - acc: 0.9618 - val_loss: 0.3088 - val_acc: 0.9050\n",
      "Epoch 155/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.0968 - acc: 0.9655 - val_loss: 0.3020 - val_acc: 0.9082\n",
      "Epoch 156/300\n",
      "5683/5683 [==============================] - 1s 114us/step - loss: 0.0964 - acc: 0.9666 - val_loss: 0.3109 - val_acc: 0.9071\n",
      "Epoch 157/300\n",
      "5683/5683 [==============================] - 1s 128us/step - loss: 0.1051 - acc: 0.9611 - val_loss: 0.3249 - val_acc: 0.9047\n",
      "Epoch 158/300\n",
      "5683/5683 [==============================] - 1s 133us/step - loss: 0.1004 - acc: 0.9653 - val_loss: 0.3174 - val_acc: 0.9076\n",
      "Epoch 159/300\n",
      "5683/5683 [==============================] - 1s 136us/step - loss: 0.1035 - acc: 0.9632 - val_loss: 0.3053 - val_acc: 0.9050\n",
      "Epoch 160/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.1023 - acc: 0.9639 - val_loss: 0.2931 - val_acc: 0.9066\n",
      "Epoch 161/300\n",
      "5683/5683 [==============================] - 1s 127us/step - loss: 0.0972 - acc: 0.9636 - val_loss: 0.3092 - val_acc: 0.9103\n",
      "Epoch 162/300\n",
      "5683/5683 [==============================] - 1s 114us/step - loss: 0.0897 - acc: 0.9666 - val_loss: 0.3128 - val_acc: 0.9068\n",
      "Epoch 163/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.1039 - acc: 0.9638 - val_loss: 0.3001 - val_acc: 0.9116\n",
      "Epoch 164/300\n",
      "5683/5683 [==============================] - 1s 116us/step - loss: 0.0841 - acc: 0.9708 - val_loss: 0.3688 - val_acc: 0.9005\n",
      "Epoch 165/300\n",
      "5683/5683 [==============================] - 1s 128us/step - loss: 0.1014 - acc: 0.9671 - val_loss: 0.3024 - val_acc: 0.9089\n",
      "Epoch 166/300\n",
      "5683/5683 [==============================] - 1s 134us/step - loss: 0.0957 - acc: 0.9671 - val_loss: 0.3283 - val_acc: 0.9050\n",
      "Epoch 167/300\n",
      "5683/5683 [==============================] - 1s 134us/step - loss: 0.0955 - acc: 0.9660 - val_loss: 0.3331 - val_acc: 0.9023\n",
      "Epoch 168/300\n",
      "5683/5683 [==============================] - 1s 147us/step - loss: 0.0869 - acc: 0.9710 - val_loss: 0.3160 - val_acc: 0.9103\n",
      "Epoch 169/300\n",
      "5683/5683 [==============================] - 1s 143us/step - loss: 0.1035 - acc: 0.9638 - val_loss: 0.2933 - val_acc: 0.9055\n",
      "Epoch 170/300\n",
      "5683/5683 [==============================] - 1s 126us/step - loss: 0.1091 - acc: 0.9632 - val_loss: 0.3023 - val_acc: 0.9066\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.0830 - acc: 0.9708 - val_loss: 0.3221 - val_acc: 0.9100\n",
      "Epoch 172/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.0907 - acc: 0.9676 - val_loss: 0.3473 - val_acc: 0.9013\n",
      "Epoch 173/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.1003 - acc: 0.9639 - val_loss: 0.3293 - val_acc: 0.9047\n",
      "Epoch 174/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0912 - acc: 0.9685 - val_loss: 0.3420 - val_acc: 0.9053\n",
      "Epoch 175/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0952 - acc: 0.9676 - val_loss: 0.3142 - val_acc: 0.9034\n",
      "Epoch 176/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.1024 - acc: 0.9632 - val_loss: 0.3356 - val_acc: 0.9029\n",
      "Epoch 177/300\n",
      "5683/5683 [==============================] - 1s 124us/step - loss: 0.0978 - acc: 0.9674 - val_loss: 0.3279 - val_acc: 0.9076\n",
      "Epoch 178/300\n",
      "5683/5683 [==============================] - 1s 110us/step - loss: 0.0883 - acc: 0.9667 - val_loss: 0.3421 - val_acc: 0.9010\n",
      "Epoch 179/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.0906 - acc: 0.9682 - val_loss: 0.3324 - val_acc: 0.9092\n",
      "Epoch 180/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.0976 - acc: 0.9650 - val_loss: 0.3241 - val_acc: 0.9097\n",
      "Epoch 181/300\n",
      "5683/5683 [==============================] - 1s 125us/step - loss: 0.0839 - acc: 0.9673 - val_loss: 0.3237 - val_acc: 0.9047\n",
      "Epoch 182/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0893 - acc: 0.9703 - val_loss: 0.3155 - val_acc: 0.9047\n",
      "Epoch 183/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0865 - acc: 0.9706 - val_loss: 0.3465 - val_acc: 0.9034\n",
      "Epoch 184/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0860 - acc: 0.9704 - val_loss: 0.3004 - val_acc: 0.9087\n",
      "Epoch 185/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0943 - acc: 0.9706 - val_loss: 0.3118 - val_acc: 0.9079\n",
      "Epoch 186/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.0816 - acc: 0.9741 - val_loss: 0.3221 - val_acc: 0.9103\n",
      "Epoch 187/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.0905 - acc: 0.9659 - val_loss: 0.3443 - val_acc: 0.9066\n",
      "Epoch 188/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.0891 - acc: 0.9697 - val_loss: 0.3173 - val_acc: 0.9037\n",
      "Epoch 189/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.0903 - acc: 0.9680 - val_loss: 0.3465 - val_acc: 0.9042\n",
      "Epoch 190/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0890 - acc: 0.9690 - val_loss: 0.3150 - val_acc: 0.9087\n",
      "Epoch 191/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0879 - acc: 0.9706 - val_loss: 0.3329 - val_acc: 0.9055\n",
      "Epoch 192/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0905 - acc: 0.9690 - val_loss: 0.3317 - val_acc: 0.9084\n",
      "Epoch 193/300\n",
      "5683/5683 [==============================] - 1s 133us/step - loss: 0.0921 - acc: 0.9682 - val_loss: 0.3106 - val_acc: 0.9100\n",
      "Epoch 194/300\n",
      "5683/5683 [==============================] - 1s 116us/step - loss: 0.0862 - acc: 0.9682 - val_loss: 0.3388 - val_acc: 0.9071\n",
      "Epoch 195/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.0914 - acc: 0.9689 - val_loss: 0.3127 - val_acc: 0.9105\n",
      "Epoch 196/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.0808 - acc: 0.9717 - val_loss: 0.3087 - val_acc: 0.9116\n",
      "Epoch 197/300\n",
      "5683/5683 [==============================] - 1s 113us/step - loss: 0.0840 - acc: 0.9703 - val_loss: 0.3260 - val_acc: 0.9058\n",
      "Epoch 198/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0854 - acc: 0.9708 - val_loss: 0.3389 - val_acc: 0.9076\n",
      "Epoch 199/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0842 - acc: 0.9713 - val_loss: 0.3061 - val_acc: 0.9103\n",
      "Epoch 200/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0825 - acc: 0.9722 - val_loss: 0.3157 - val_acc: 0.9111\n",
      "Epoch 201/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0764 - acc: 0.9733 - val_loss: 0.3364 - val_acc: 0.9076\n",
      "Epoch 202/300\n",
      "5683/5683 [==============================] - 1s 123us/step - loss: 0.0848 - acc: 0.9680 - val_loss: 0.3124 - val_acc: 0.9045\n",
      "Epoch 203/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.0744 - acc: 0.9752 - val_loss: 0.3679 - val_acc: 0.9008\n",
      "Epoch 204/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.0830 - acc: 0.9706 - val_loss: 0.3477 - val_acc: 0.9039\n",
      "Epoch 205/300\n",
      "5683/5683 [==============================] - 1s 113us/step - loss: 0.0856 - acc: 0.9699 - val_loss: 0.3146 - val_acc: 0.9129\n",
      "Epoch 206/300\n",
      "5683/5683 [==============================] - 1s 126us/step - loss: 0.0880 - acc: 0.9694 - val_loss: 0.3437 - val_acc: 0.9068\n",
      "Epoch 207/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0845 - acc: 0.9727 - val_loss: 0.3438 - val_acc: 0.9087\n",
      "Epoch 208/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0733 - acc: 0.9743 - val_loss: 0.3385 - val_acc: 0.9071\n",
      "Epoch 209/300\n",
      "5683/5683 [==============================] - 1s 130us/step - loss: 0.0780 - acc: 0.9711 - val_loss: 0.3340 - val_acc: 0.9105\n",
      "Epoch 210/300\n",
      "5683/5683 [==============================] - 1s 130us/step - loss: 0.0869 - acc: 0.9690 - val_loss: 0.3154 - val_acc: 0.9079\n",
      "Epoch 211/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.0756 - acc: 0.9708 - val_loss: 0.3321 - val_acc: 0.9058\n",
      "Epoch 212/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.0824 - acc: 0.9722 - val_loss: 0.3543 - val_acc: 0.9034\n",
      "Epoch 213/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.0783 - acc: 0.9718 - val_loss: 0.3517 - val_acc: 0.9082\n",
      "Epoch 214/300\n",
      "5683/5683 [==============================] - 1s 120us/step - loss: 0.0808 - acc: 0.9699 - val_loss: 0.3261 - val_acc: 0.9074\n",
      "Epoch 215/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0679 - acc: 0.9761 - val_loss: 0.3316 - val_acc: 0.9097\n",
      "Epoch 216/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0881 - acc: 0.9682 - val_loss: 0.3369 - val_acc: 0.9068\n",
      "Epoch 217/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0837 - acc: 0.9727 - val_loss: 0.3354 - val_acc: 0.9063\n",
      "Epoch 218/300\n",
      "5683/5683 [==============================] - 1s 133us/step - loss: 0.0740 - acc: 0.9743 - val_loss: 0.4064 - val_acc: 0.9029\n",
      "Epoch 219/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.0718 - acc: 0.9748 - val_loss: 0.3563 - val_acc: 0.9018\n",
      "Epoch 220/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.0629 - acc: 0.9782 - val_loss: 0.3607 - val_acc: 0.9063\n",
      "Epoch 221/300\n",
      "5683/5683 [==============================] - 1s 112us/step - loss: 0.0748 - acc: 0.9755 - val_loss: 0.3570 - val_acc: 0.9071\n",
      "Epoch 222/300\n",
      "5683/5683 [==============================] - 1s 114us/step - loss: 0.0758 - acc: 0.9713 - val_loss: 0.3548 - val_acc: 0.9084\n",
      "Epoch 223/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0849 - acc: 0.9720 - val_loss: 0.3333 - val_acc: 0.9042\n",
      "Epoch 224/300\n",
      "5683/5683 [==============================] - 1s 134us/step - loss: 0.0864 - acc: 0.9706 - val_loss: 0.3417 - val_acc: 0.9039\n",
      "Epoch 225/300\n",
      "5683/5683 [==============================] - 1s 134us/step - loss: 0.0718 - acc: 0.9748 - val_loss: 0.3420 - val_acc: 0.9084\n",
      "Epoch 226/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0801 - acc: 0.9710 - val_loss: 0.3418 - val_acc: 0.9018\n",
      "Epoch 227/300\n",
      "5683/5683 [==============================] - 1s 121us/step - loss: 0.0851 - acc: 0.9708 - val_loss: 0.3452 - val_acc: 0.9013\n",
      "Epoch 228/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.0790 - acc: 0.9731 - val_loss: 0.3376 - val_acc: 0.9092\n",
      "Epoch 229/300\n",
      "5683/5683 [==============================] - 1s 127us/step - loss: 0.0826 - acc: 0.9725 - val_loss: 0.3391 - val_acc: 0.9037\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5683/5683 [==============================] - 1s 116us/step - loss: 0.0791 - acc: 0.9717 - val_loss: 0.3428 - val_acc: 0.9047\n",
      "Epoch 231/300\n",
      "5683/5683 [==============================] - 1s 116us/step - loss: 0.0869 - acc: 0.9718 - val_loss: 0.3476 - val_acc: 0.9042\n",
      "Epoch 232/300\n",
      "5683/5683 [==============================] - 1s 114us/step - loss: 0.0715 - acc: 0.9764 - val_loss: 0.3428 - val_acc: 0.9039\n",
      "Epoch 233/300\n",
      "5683/5683 [==============================] - 1s 130us/step - loss: 0.0730 - acc: 0.9734 - val_loss: 0.3380 - val_acc: 0.9053\n",
      "Epoch 234/300\n",
      "5683/5683 [==============================] - 1s 129us/step - loss: 0.0742 - acc: 0.9750 - val_loss: 0.3680 - val_acc: 0.9034\n",
      "Epoch 235/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0766 - acc: 0.9741 - val_loss: 0.3836 - val_acc: 0.9023\n",
      "Epoch 236/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0848 - acc: 0.9725 - val_loss: 0.3408 - val_acc: 0.9039\n",
      "Epoch 237/300\n",
      "5683/5683 [==============================] - 1s 137us/step - loss: 0.0803 - acc: 0.9722 - val_loss: 0.3439 - val_acc: 0.9010\n",
      "Epoch 238/300\n",
      "5683/5683 [==============================] - 1s 136us/step - loss: 0.0719 - acc: 0.9752 - val_loss: 0.3481 - val_acc: 0.9060\n",
      "Epoch 239/300\n",
      "5683/5683 [==============================] - 1s 124us/step - loss: 0.0727 - acc: 0.9729 - val_loss: 0.3691 - val_acc: 0.9071\n",
      "Epoch 240/300\n",
      "5683/5683 [==============================] - 1s 147us/step - loss: 0.0649 - acc: 0.9771 - val_loss: 0.3732 - val_acc: 0.9066\n",
      "Epoch 241/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0750 - acc: 0.9713 - val_loss: 0.3489 - val_acc: 0.9039\n",
      "Epoch 242/300\n",
      "5683/5683 [==============================] - 1s 109us/step - loss: 0.0768 - acc: 0.9771 - val_loss: 0.3603 - val_acc: 0.9079\n",
      "Epoch 243/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.0717 - acc: 0.9755 - val_loss: 0.3562 - val_acc: 0.9082\n",
      "Epoch 244/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0681 - acc: 0.9755 - val_loss: 0.3625 - val_acc: 0.9082\n",
      "Epoch 245/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0702 - acc: 0.9757 - val_loss: 0.3698 - val_acc: 0.9068\n",
      "Epoch 246/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0682 - acc: 0.9792 - val_loss: 0.3539 - val_acc: 0.9111\n",
      "Epoch 247/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0715 - acc: 0.9743 - val_loss: 0.3464 - val_acc: 0.9055\n",
      "Epoch 248/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0699 - acc: 0.9769 - val_loss: 0.3705 - val_acc: 0.9026\n",
      "Epoch 249/300\n",
      "5683/5683 [==============================] - 1s 137us/step - loss: 0.0761 - acc: 0.9766 - val_loss: 0.3461 - val_acc: 0.9087\n",
      "Epoch 250/300\n",
      "5683/5683 [==============================] - 1s 111us/step - loss: 0.0648 - acc: 0.9768 - val_loss: 0.3651 - val_acc: 0.9026\n",
      "Epoch 251/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.0798 - acc: 0.9740 - val_loss: 0.3495 - val_acc: 0.9089\n",
      "Epoch 252/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.0705 - acc: 0.9764 - val_loss: 0.3504 - val_acc: 0.9084\n",
      "Epoch 253/300\n",
      "5683/5683 [==============================] - 1s 121us/step - loss: 0.0599 - acc: 0.9785 - val_loss: 0.3642 - val_acc: 0.9053\n",
      "Epoch 254/300\n",
      "5683/5683 [==============================] - 1s 130us/step - loss: 0.0639 - acc: 0.9789 - val_loss: 0.3636 - val_acc: 0.9042\n",
      "Epoch 255/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0748 - acc: 0.9757 - val_loss: 0.3597 - val_acc: 0.9084\n",
      "Epoch 256/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0724 - acc: 0.9773 - val_loss: 0.3594 - val_acc: 0.9060\n",
      "Epoch 257/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0792 - acc: 0.9734 - val_loss: 0.3758 - val_acc: 0.9066\n",
      "Epoch 258/300\n",
      "5683/5683 [==============================] - 1s 122us/step - loss: 0.0600 - acc: 0.9796 - val_loss: 0.3728 - val_acc: 0.9053\n",
      "Epoch 259/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.0764 - acc: 0.9703 - val_loss: 0.3861 - val_acc: 0.9029\n",
      "Epoch 260/300\n",
      "5683/5683 [==============================] - 1s 123us/step - loss: 0.0743 - acc: 0.9754 - val_loss: 0.3820 - val_acc: 0.9066\n",
      "Epoch 261/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.0645 - acc: 0.9775 - val_loss: 0.3827 - val_acc: 0.9058\n",
      "Epoch 262/300\n",
      "5683/5683 [==============================] - 1s 124us/step - loss: 0.0610 - acc: 0.9794 - val_loss: 0.3770 - val_acc: 0.9042\n",
      "Epoch 263/300\n",
      "5683/5683 [==============================] - 1s 124us/step - loss: 0.0803 - acc: 0.9738 - val_loss: 0.3557 - val_acc: 0.9119\n",
      "Epoch 264/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0678 - acc: 0.9778 - val_loss: 0.3706 - val_acc: 0.9071\n",
      "Epoch 265/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0778 - acc: 0.9731 - val_loss: 0.3593 - val_acc: 0.9082\n",
      "Epoch 266/300\n",
      "5683/5683 [==============================] - 1s 130us/step - loss: 0.0678 - acc: 0.9769 - val_loss: 0.3561 - val_acc: 0.9047\n",
      "Epoch 267/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0708 - acc: 0.9761 - val_loss: 0.3668 - val_acc: 0.9029\n",
      "Epoch 268/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.0740 - acc: 0.9778 - val_loss: 0.3595 - val_acc: 0.9055\n",
      "Epoch 269/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.0783 - acc: 0.9733 - val_loss: 0.3509 - val_acc: 0.9031\n",
      "Epoch 270/300\n",
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.0636 - acc: 0.9798 - val_loss: 0.3479 - val_acc: 0.9103\n",
      "Epoch 271/300\n",
      "5683/5683 [==============================] - 1s 122us/step - loss: 0.0595 - acc: 0.9805 - val_loss: 0.3467 - val_acc: 0.9076\n",
      "Epoch 272/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0655 - acc: 0.9782 - val_loss: 0.3534 - val_acc: 0.9082\n",
      "Epoch 273/300\n",
      "5683/5683 [==============================] - 1s 133us/step - loss: 0.0756 - acc: 0.9761 - val_loss: 0.3491 - val_acc: 0.9087\n",
      "Epoch 274/300\n",
      "5683/5683 [==============================] - 1s 131us/step - loss: 0.0669 - acc: 0.9780 - val_loss: 0.3610 - val_acc: 0.9068\n",
      "Epoch 275/300\n",
      "5683/5683 [==============================] - 1s 133us/step - loss: 0.0746 - acc: 0.9740 - val_loss: 0.3531 - val_acc: 0.9100\n",
      "Epoch 276/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0598 - acc: 0.9771 - val_loss: 0.3630 - val_acc: 0.9100\n",
      "Epoch 277/300\n",
      "5683/5683 [==============================] - 1s 126us/step - loss: 0.0677 - acc: 0.9777 - val_loss: 0.3473 - val_acc: 0.9095\n",
      "Epoch 278/300\n",
      "5683/5683 [==============================] - 1s 125us/step - loss: 0.0779 - acc: 0.9761 - val_loss: 0.3456 - val_acc: 0.9068\n",
      "Epoch 279/300\n",
      "5683/5683 [==============================] - 1s 125us/step - loss: 0.0764 - acc: 0.9764 - val_loss: 0.3528 - val_acc: 0.9031\n",
      "Epoch 280/300\n",
      "5683/5683 [==============================] - 1s 140us/step - loss: 0.0718 - acc: 0.9754 - val_loss: 0.3594 - val_acc: 0.9060\n",
      "Epoch 281/300\n",
      "5683/5683 [==============================] - 1s 144us/step - loss: 0.0668 - acc: 0.9766 - val_loss: 0.3460 - val_acc: 0.9029\n",
      "Epoch 282/300\n",
      "5683/5683 [==============================] - 1s 124us/step - loss: 0.0685 - acc: 0.9761 - val_loss: 0.3634 - val_acc: 0.9042\n",
      "Epoch 283/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0646 - acc: 0.9775 - val_loss: 0.3874 - val_acc: 0.9047\n",
      "Epoch 284/300\n",
      "5683/5683 [==============================] - 1s 133us/step - loss: 0.0646 - acc: 0.9762 - val_loss: 0.3518 - val_acc: 0.9063\n",
      "Epoch 285/300\n",
      "5683/5683 [==============================] - 1s 132us/step - loss: 0.0651 - acc: 0.9782 - val_loss: 0.3865 - val_acc: 0.9034\n",
      "Epoch 286/300\n",
      "5683/5683 [==============================] - 1s 133us/step - loss: 0.0581 - acc: 0.9780 - val_loss: 0.3453 - val_acc: 0.9095\n",
      "Epoch 287/300\n",
      "5683/5683 [==============================] - 1s 119us/step - loss: 0.0527 - acc: 0.9826 - val_loss: 0.3711 - val_acc: 0.9055\n",
      "Epoch 288/300\n",
      "5683/5683 [==============================] - 1s 118us/step - loss: 0.0694 - acc: 0.9780 - val_loss: 0.3969 - val_acc: 0.9013\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5683/5683 [==============================] - 1s 117us/step - loss: 0.0632 - acc: 0.9762 - val_loss: 0.3589 - val_acc: 0.9087\n",
      "Epoch 290/300\n",
      "5683/5683 [==============================] - 1s 122us/step - loss: 0.0519 - acc: 0.9819 - val_loss: 0.3952 - val_acc: 0.9060\n",
      "Epoch 291/300\n",
      "5683/5683 [==============================] - 1s 157us/step - loss: 0.0637 - acc: 0.9778 - val_loss: 0.3528 - val_acc: 0.9092\n",
      "Epoch 292/300\n",
      "5683/5683 [==============================] - 1s 148us/step - loss: 0.0671 - acc: 0.9773 - val_loss: 0.3642 - val_acc: 0.9060\n",
      "Epoch 293/300\n",
      "5683/5683 [==============================] - 1s 149us/step - loss: 0.0619 - acc: 0.9787 - val_loss: 0.3825 - val_acc: 0.9079\n",
      "Epoch 294/300\n",
      "5683/5683 [==============================] - 1s 152us/step - loss: 0.0650 - acc: 0.9789 - val_loss: 0.3642 - val_acc: 0.9026\n",
      "Epoch 295/300\n",
      "5683/5683 [==============================] - 1s 148us/step - loss: 0.0595 - acc: 0.9792 - val_loss: 0.3828 - val_acc: 0.9034\n",
      "Epoch 296/300\n",
      "5683/5683 [==============================] - 1s 133us/step - loss: 0.0566 - acc: 0.9789 - val_loss: 0.3827 - val_acc: 0.9068\n",
      "Epoch 297/300\n",
      "5683/5683 [==============================] - 1s 143us/step - loss: 0.0679 - acc: 0.9759 - val_loss: 0.3723 - val_acc: 0.9058\n",
      "Epoch 298/300\n",
      "5683/5683 [==============================] - 1s 116us/step - loss: 0.0659 - acc: 0.9796 - val_loss: 0.3668 - val_acc: 0.9092\n",
      "Epoch 299/300\n",
      "5683/5683 [==============================] - 1s 135us/step - loss: 0.0726 - acc: 0.9757 - val_loss: 0.3650 - val_acc: 0.9108\n",
      "Epoch 300/300\n",
      "5683/5683 [==============================] - 1s 126us/step - loss: 0.0664 - acc: 0.9766 - val_loss: 0.3692 - val_acc: 0.9068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f12788b4f98>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2,2), activation='relu',input_shape=(20,11,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "model.fit(X_train, y_train_hot,batch_size=100, epochs=300, verbose=1, validation_data=(X_test, y_test_hot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('/home/aaa/aatresh/Audio Processing/data/go/0a9f9af7_nohash_0.wav')\n",
    "sample_reshaped = sample.reshape(1,20,11,1)\n",
    "print(get_labels()[0][np.argmax(model.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pydub/utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-0f2a8806632b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import sys\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-272b01715492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "import time\n",
    "\n",
    "\n",
    "try:\n",
    "        mySock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        print (\"Socket created\")\n",
    "\n",
    "except socket.error:\n",
    "        print (\"Socket connection failed\")\n",
    "\n",
    "port = 8888\n",
    "try:\n",
    "        mySock.connect((\"192.168.43.195\", port))\n",
    "        print (\"Connected to RPi!\")\n",
    "except socket.error:\n",
    "        print (\"Not able to connect\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 3\n",
    "WAVE_OUTPUT_FILENAME = \"out.wav\"\n",
    "while True:\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "        print(\"* recording\")\n",
    "\n",
    "        frames = []\n",
    "\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "        print(\"* done recording\")\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "        \n",
    "        recording = AudioSegment.from_wav(\"./out.wav\")\n",
    "        recording+=20\n",
    "        recording.export(\"./out.wav\", format=\"wav\")\n",
    "\n",
    "        print(\"Before the sleep statement\")\n",
    "        mixer.init(frequency=44100)\n",
    "        mixer.music.load(\"./out.wav\")\n",
    "        mixer.music.play()\n",
    "        time.sleep(5)\n",
    "        print(\"After the sleep statement\")\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "filenames=os.listdir(\"/home/aaa/aatresh/Audio Processing/New folder/\")\n",
    "\n",
    "while(1):\n",
    " \n",
    "\n",
    "\n",
    "    for f in filenames:\n",
    "        sample = wav2mfcc(\"/home/aaa/aatresh/Audio Processing/New folder/\"+f)\n",
    "        sample_reshaped = sample.reshape(1,20,11,1)\n",
    "        message = get_labels(\"/home/aaa/aatresh/Audio Processing/data/\")[0][np.argmax(model.predict(sample_reshaped))]   \n",
    "\n",
    "        mixer.init(frequency=44100)\n",
    "        mixer.music.load(\"/home/aaa/aatresh/Audio Processing/New folder/\"+f)\n",
    "        mixer.music.play()\n",
    "        \n",
    "        print(message)\n",
    "        mySock.send(message.encode())\n",
    "        data = mySock.recv(1024).decode()\n",
    "        print (\"Received from server: \" + data)\n",
    "        time.sleep(2)\n",
    "    #    message = input(\"->\")\n",
    "        \n",
    "\n",
    "#message=\"go\"\n",
    "\"\"\"\n",
    "while(1):\n",
    "    mySock.send(message.encode())\n",
    "    data = mySock.recv(1024).decode()\n",
    "    print (\"Received from server: \" + data)\n",
    "\"\"\"\n",
    "\n",
    "mySock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
